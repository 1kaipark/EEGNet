{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "OG PyTorch code by: Sriram Ravindran, sriram@ucsd.edu\n",
    "\n",
    "Original paper - https://arxiv.org/abs/1611.08024\n",
    "\n",
    "Please reach out to me if you spot an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEGNet core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Boring ahh imports\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# MNE stuff\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here's the description from the paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"EEGNet.png\" style=\"width: 700px; float:left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the basic model + does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we create an EEGNet class, with 2 arguments - channels, and samples. \n",
    "- first convolution kernel will have a width corresponding to the number of EEG channels/samples\n",
    "- based on 'reshape value'- adjust fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, channels, samples, verbose = True):\n",
    "        super(EEGNet, self).__init__()\n",
    "\n",
    "        self.kernellength = channels\n",
    "        self.T = samples # AKA samples\n",
    "\n",
    "        self.filter_sizing = 16\n",
    "\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Layer 1\n",
    "        # input shape [n (?), kernel height, samples, kernel width]\n",
    "        # corresponds [n (?), kern. h (=1)., time pts, kern w = channels]\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = self.filter_sizing, kernel_size = (1, self.kernellength), padding = 0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(self.filter_sizing, False)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((self.filter_sizing, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(in_channels = 1, out_channels = 4, kernel_size = (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "\n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(in_channels = 4, out_channels = 4, kernel_size = (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "        \n",
    "        # FC Layer\n",
    "        # NOTE: This dimension will depend on the number of timestamps per sample in your data.\n",
    "        # I have 120 timepoints. \n",
    "        # self.fc1 = nn.Linear(4 * 2 * int(self.T/16), 1) # adjust shape, used to be self.T/16??\n",
    "        self.fc1 = nn.Linear(240, 1)\n",
    "        # NOTE: if error, sadly must recursively change the first value here to the \"reshape value\" in output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        if self.verbose:\n",
    "            print(\"Layer 1 input:\", x.shape)\n",
    "\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Layer 1 output:\", x.shape)\n",
    "\n",
    "        # Layer 2\n",
    "        if self.verbose:\n",
    "            print(\"Layer 2 input:\", x.shape)\n",
    "\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Layer 2 output:\", x.shape)\n",
    "\n",
    "        # Layer 3\n",
    "        if self.verbose:\n",
    "            print(\"Layer 3 input:\", x.shape)\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        if self.verbose:\n",
    "            print(\"Layer 3 output:\", x.shape, \"layer 3 size: \", x.size)\n",
    "\n",
    "\n",
    "        print(f\"Size of x after pooling3: {x.shape}\")\n",
    "        print(f\"reshape value: {x.shape[1]*x.shape[2]*x.shape[3]}\")\n",
    "\n",
    "        # FC Layer\n",
    "        # x = x.reshape(-1, 4 * 2 * int(self.T/16))\n",
    "        x = x.reshape(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        if self.verbose:\n",
    "            print(\"FC Layer input:\", x.shape)\n",
    "            print(f\"testing {self.fc1}\")\n",
    "\n",
    "        x = F.sigmoid(self.fc1(x)) # doesn't work with [32, 156] ?\n",
    "        if self.verbose:\n",
    "            print(\"FC Layer output:\", x.shape)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 input: torch.Size([32, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([32, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([32, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([32, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([32, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([32, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd0d0>\n",
      "Size of x after pooling3: torch.Size([32, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([32, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([32, 1])\n",
      "tensor([[0.6869],\n",
      "        [0.7813],\n",
      "        [0.4905],\n",
      "        [0.8037],\n",
      "        [0.8119],\n",
      "        [0.7101],\n",
      "        [0.6006],\n",
      "        [0.6868],\n",
      "        [0.4038],\n",
      "        [0.6915],\n",
      "        [0.8557],\n",
      "        [0.6306],\n",
      "        [0.6760],\n",
      "        [0.6767],\n",
      "        [0.7277],\n",
      "        [0.7271],\n",
      "        [0.6768],\n",
      "        [0.5941],\n",
      "        [0.7155],\n",
      "        [0.7131],\n",
      "        [0.6176],\n",
      "        [0.7202],\n",
      "        [0.6850],\n",
      "        [0.4810],\n",
      "        [0.4809],\n",
      "        [0.5813],\n",
      "        [0.6060],\n",
      "        [0.5515],\n",
      "        [0.7600],\n",
      "        [0.5194],\n",
      "        [0.7869],\n",
      "        [0.6697]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# instantiate model + brief test, retro-fit reshape value if you change channels + samples\n",
    "testkern = 64\n",
    "testT = 481\n",
    "net = EEGNet(channels=testkern, samples=testT)\n",
    "print (net.forward(Variable(torch.Tensor(np.random.rand(32, 1, testT, testkern))))) # again, n, kern height, samples, kern width/EEG channels/electrodes\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate function returns values of different criteria like accuracy, precision etc. \n",
    "In case you face memory overflow issues, use batch size to control how many samples get evaluated at one time. Use a batch_size that is a factor of length of samples. This ensures that you won't miss any samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(net, X, Y, params = [\"acc\"]):\n",
    "    results = []\n",
    "    batch_size = 100\n",
    "    \n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(len(X) // batch_size):\n",
    "        s = i*batch_size\n",
    "        e = i*batch_size+batch_size\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(X[s:e]))\n",
    "        pred = net(inputs)\n",
    "        \n",
    "        predicted.append(pred.data.cpu().numpy())\n",
    "        \n",
    "        \n",
    "    inputs = Variable(torch.from_numpy(X))\n",
    "    predicted = net(inputs)\n",
    "    \n",
    "    predicted = predicted.data.cpu().numpy()\n",
    "    \n",
    "    for param in params:\n",
    "        if param == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted)))\n",
    "        if param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted))\n",
    "        if param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted)))\n",
    "        if param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted)))\n",
    "        if param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted))\n",
    "            recall = recall_score(Y, np.round(predicted))\n",
    "            results.append(2*precision*recall/ (precision+recall))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### run method (same code, just packed into a method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_net(net, batch_size, num_train_epochs, optimizer, criterion, X_train, y_train, X_val, y_val, X_test, y_test, title):\n",
    "\n",
    "    #batch_size = 32\n",
    "    train_accuracy_scores = []\n",
    "    val_accuracy_scores = []\n",
    "\n",
    "    for epoch in range(num_train_epochs):  # loop over the dataset multiple times\n",
    "        print (\"\\nEpoch \", epoch)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for i in range(len(X_train) // batch_size-1):\n",
    "            s = i * batch_size\n",
    "            e = i * batch_size+batch_size\n",
    "            \n",
    "            inputs = torch.from_numpy(X_train[s:e])\n",
    "            labels = torch.FloatTensor(np.array([y_train[s:e]]).T * 1.0)\n",
    "            \n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            print(f\"outputs.shape: {outputs.shape}\")\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # running_loss += loss.data[0]\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation accuracy\n",
    "        params = [\"acc\", \"auc\", \"fmeasure\"]\n",
    "        print (params)\n",
    "        print (\"Training Loss \", running_loss)\n",
    "        print (\"Train - \", evaluate(net, X_train, y_train, params))\n",
    "        print (\"Validation - \", evaluate(net, X_val, y_val, params))\n",
    "        print (\"Test - \", evaluate(net, X_test, y_test, params))\n",
    "\n",
    "        train_accuracy = evaluate(net, X_train, y_train, params = [\"acc\"])[0]\n",
    "        train_accuracy_scores.append(train_accuracy)\n",
    "\n",
    "        val_accuracy = evaluate(net, X_val, y_val, params = [\"acc\"])[0]\n",
    "        val_accuracy_scores.append(val_accuracy)\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(range(num_train_epochs), train_accuracy_scores, label = 'train accuracy')\n",
    "    plt.plot(range(num_train_epochs), val_accuracy_scores, label = 'val accuracy')\n",
    "\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(f'accuracy vs. epoch {title}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Model using MNE EEGBCI Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import and shape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/applelaptop/mne_data_test/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/applelaptop/mne_data_test/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from /Users/applelaptop/mne_data_test/MNE-eegbci-data/files/eegmmidb/1.0.0/S001/S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 7 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 7.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 6.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 45 events and 481 original time points ...\n",
      "0 bad epochs dropped\n",
      "(45, 64, 481)\n",
      "(45,)\n",
      "[1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0\n",
      " 1 0 1 1 0 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# # Set parameters and read data\n",
    "\n",
    "# avoid classification of evoked responses by using epochs that start 1s after\n",
    "# cue onset.\n",
    "tmin, tmax = -1.0, 2.0\n",
    "event_id = dict(hands=2, feet=3)\n",
    "subject = 1\n",
    "runs = [6, 10, 14]  # motor imagery: hands vs feet\n",
    "\n",
    "raw_fnames = eegbci.load_data(subject, runs)\n",
    "raw = mne.io.concatenate_raws([mne.io.read_raw_edf(f, preload=True) for f in raw_fnames])\n",
    "eegbci.standardize(raw)  # set channel names\n",
    "montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "raw.set_montage(montage)\n",
    "\n",
    "# Apply band-pass filter\n",
    "raw.filter(7.0, 30.0, fir_design=\"firwin\", skip_by_annotation=\"edge\")\n",
    "\n",
    "events, _ = mne.events_from_annotations(raw, event_id=dict(T1=2, T2=3))\n",
    "\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False, exclude=\"bads\")\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    event_id,\n",
    "    tmin,\n",
    "    tmax,\n",
    "    proj=True,\n",
    "    picks=picks,\n",
    "    baseline=None,\n",
    "    preload=True,\n",
    ")\n",
    "epochs_train = epochs.copy().crop(tmin=1.0, tmax=2.0)\n",
    "labels = epochs.events[:, -1] - 2\n",
    "\n",
    "print(epochs.get_data().shape) # 481 samps\n",
    "print(labels.shape)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 64, 481)\n",
      "(45, 1, 481, 64)\n",
      "(45,)\n",
      "train: (31, 1, 481, 64) test: (7, 1, 481, 64) val: (7, 1, 481, 64)\n"
     ]
    }
   ],
   "source": [
    "X = epochs.get_data().astype('float32')\n",
    "print(X.shape)\n",
    "X = X.reshape (45, 1, 64, 481)\n",
    "X = X.transpose(0, 1, 3, 2)\n",
    "print(X.shape)\n",
    "\n",
    "y = labels\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "X_val, X_test, y_val, y_test = train_test_split (X_temp, y_temp, test_size = 0.5, random_state = 42)\n",
    "\n",
    "print(f\"train: {X_train.shape} test: {X_test.shape} val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define and run EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  0\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2480>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dde81d0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.5783711075782776\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8860>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.6451612903225806, 0.5966386554621849, 0.7555555555555554]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9f30>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.5714285714285714, 0.75, 0.6666666666666666]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddff60>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.16666666666666669, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14ede4130>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f886bb0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  1\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e24d0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dde8090>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.337765395641327\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9c10>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.5806451612903226, 0.5630252100840336, 0.7111111111111111]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2110>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.9166666666666666, 0.6]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f886ca0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.41666666666666663, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e22f0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8869d0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  2\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddfc90>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8720>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.4166423678398132\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9c60>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.5806451612903226, 0.6176470588235294, 0.6666666666666667]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b89f0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.5833333333333333, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e21b0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.2857142857142857, 0.5, 0.4444444444444445]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd080>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8869d0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  3\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e22f0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddfa10>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.3463521003723145\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba110>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.5806451612903226, 0.5882352941176471, 0.6666666666666667]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9d50>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.5833333333333334, 0.3333333333333333]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14ede4130>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.5833333333333333, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f886a70>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2480>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  4\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dde8090>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddff60>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.1873779296875\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b82c0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.6129032258064516, 0.5588235294117647, 0.6842105263157895]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9e40>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.7142857142857143, 0.6666666666666666, 0.6666666666666666]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba0c0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5, 0.6666666666666665]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f886a70>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9b20>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  5\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddfc90>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.2057084441184998\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9df0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.6451612903225806, 0.634453781512605, 0.717948717948718]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8310>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.16666666666666666, 0.28571428571428575]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9b70>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.16666666666666669, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b83b0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8869d0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  6\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14ede4860>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2390>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.0593985617160797\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9df0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.6129032258064516, 0.7100840336134454, 0.6666666666666667]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9d50>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.5, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8270>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.3333333333333333, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b82c0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba390>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  7\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f886a70>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14ede4860>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.1597894430160522\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e22f0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7096774193548387, 0.8067226890756303, 0.7692307692307693]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8ae0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.41666666666666663, 0.28571428571428575]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9f80>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.6666666666666666, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9e90>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9ee0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  8\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x149b865c0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.9977726340293884\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b89f0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.6774193548387096, 0.7815126050420168, 0.75]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd0d0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.5714285714285714, 0.5833333333333333, 0.6666666666666666]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9c10>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.4166666666666667, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b89f0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8a40>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  9\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e22f0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd0d0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  1.0021031498908997\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9bc0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7419354838709677, 0.7857142857142857, 0.8095238095238095]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba2f0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.5714285714285714, 0.6666666666666666, 0.6666666666666666]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2110>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5833333333333333, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9cb0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9c10>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  10\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x149b865c0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba2a0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.8370105028152466\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd080>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8387096774193549, 0.8067226890756302, 0.8717948717948718]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba1b0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.3333333333333333, 0.6]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b85e0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f886c00>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8400>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  11\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e22f0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b82c0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.8979650437831879\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8869d0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7741935483870968, 0.861344537815126, 0.8108108108108107]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b85e0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.5714285714285714, 0.41666666666666663, 0.6666666666666666]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dde84f0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8310>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba1b0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  12\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e22f0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.8713671565055847\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b83b0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.6774193548387096, 0.7731092436974789, 0.7368421052631577]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9c60>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.7142857142857143, 0.5, 0.7499999999999999]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd0d0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.25, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8720>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  13\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14ddddbc0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7c43b0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.8369539082050323\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8950>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7741935483870968, 0.8403361344537814, 0.8205128205128205]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba200>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.3333333333333333, 0.4444444444444444]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9fd0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.5833333333333333, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dde8090>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8400>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  14\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2390>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7c43b0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.8014092445373535\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8ae0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7419354838709677, 0.8025210084033614, 0.7894736842105262]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8950>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.16666666666666666, 0.4444444444444444]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba020>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.33333333333333337, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b85e0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba200>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  15\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f886bb0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.7446483373641968\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd0d0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7741935483870968, 0.8529411764705881, 0.8108108108108107]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8270>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.25, 0.4444444444444444]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba160>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9fd0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba5c0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  16\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e21b0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.830040454864502\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9cb0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8064516129032258, 0.8361344537815125, 0.85]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8770>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.3333333333333333, 0.4444444444444444]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9bc0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.41666666666666663, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba430>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9b20>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  17\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14ede41d0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9d50>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.6799018383026123\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9e40>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7741935483870968, 0.8865546218487395, 0.8205128205128205]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8400>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.3333333333333333, 0.28571428571428575]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba2a0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.5, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba4d0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8950>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  18\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2480>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8590>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.6852065026760101\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8387096774193549, 0.8403361344537815, 0.8571428571428571]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e21b0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.3333333333333333, 0.3333333333333333]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b85e0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.5, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9b20>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2390>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  19\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2570>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8770>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.5846528112888336\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8310>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7419354838709677, 0.8025210084033614, 0.7894736842105262]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba3e0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.5714285714285714, 0.25, 0.6666666666666666]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2390>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9bc0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8400>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  20\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8770>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2390>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.6296365261077881\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9bc0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8387096774193549, 0.8823529411764706, 0.8717948717948718]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8ae0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.16666666666666666, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba390>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.5, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba250>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  21\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba520>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba0c0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.7370834648609161\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9e90>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8064516129032258, 0.8613445378151261, 0.8421052631578947]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba430>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.25, 0.3333333333333333]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba430>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.4166666666666667, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7c43b0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba750>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  22\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14ede4180>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba110>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.5793083608150482\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8064516129032258, 0.8361344537815126, 0.8421052631578947]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba660>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.16666666666666666, 0.28571428571428575]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9d50>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9f80>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8360>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  23\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14ede4180>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b82c0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.5756449699401855\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dde8090>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7741935483870968, 0.8277310924369748, 0.8205128205128205]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b85e0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.3333333333333333, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8400>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5833333333333333, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba110>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8590>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  24\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba700>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14e3b84a0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.5851112604141235\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9e90>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8064516129032258, 0.8529411764705882, 0.8421052631578947]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba6b0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.25, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8770>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.41666666666666663, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8ae0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba660>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  25\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9d00>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8ae0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.4374445080757141\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba610>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8064516129032258, 0.8781512605042017, 0.8421052631578947]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8720>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.3333333333333333, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba520>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.75, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8400>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9f30>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  26\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddc950>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba020>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.5308094024658203\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8387096774193549, 0.8823529411764706, 0.8717948717948718]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8310>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.25, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba340>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.41666666666666663, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba340>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9b20>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  27\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f886bb0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9fd0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.46204355359077454\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8360>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7419354838709677, 0.8025210084033614, 0.7999999999999999]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba070>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.5, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd0d0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.33333333333333337, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8400>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8770>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  28\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9bc0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14d860040>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.5151698887348175\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba6b0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8064516129032258, 0.8697478991596639, 0.8421052631578947]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9bc0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.0, 0.0, nan]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba2f0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5833333333333333, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9f80>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba020>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  29\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8310>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3b/20z0s3dd3q153fvzct3hchb00000gn/T/ipykernel_49239/834650209.py:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  results.append(2*precision*recall/ (precision+recall))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dde8090>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.5079273581504822\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8590>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8064516129032258, 0.8823529411764706, 0.8421052631578947]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba840>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.25, 0.28571428571428575]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba340>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.5833333333333333, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba340>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba2f0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  30\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14dddd210>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8950>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.335029199719429\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8770>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8709677419354839, 0.8823529411764706, 0.8947368421052632]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9b70>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.5714285714285714, 0.6666666666666666, 0.6666666666666666]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba930>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8babb0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8310>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  31\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba250>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14d860040>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.35611939430236816\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8babb0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7741935483870968, 0.8739495798319328, 0.8205128205128205]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba480>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.41666666666666663, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baac0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.25, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba980>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b89f0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  32\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba4d0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba520>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.3942824602127075\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8400>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8387096774193549, 0.8991596638655461, 0.8648648648648648]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9b70>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.3333333333333333, 0.28571428571428575]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9b20>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba930>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9d00>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  33\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e20c0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8590>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.4524128884077072\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f7e2390>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7741935483870968, 0.8781512605042017, 0.8108108108108107]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba7a0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.5714285714285714, 0.5, 0.6666666666666666]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba160>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.41666666666666663, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba3e0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba340>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  34\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b82c0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba3e0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.3321630656719208\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba4d0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8387096774193549, 0.9201680672268907, 0.8717948717948718]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baa70>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.25, 0.28571428571428575]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14ede4130>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.5, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8770>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baac0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  35\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8869d0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8400>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.3763601928949356\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8770>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.7741935483870968, 0.861344537815126, 0.7999999999999999]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baac0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.25, 0.28571428571428575]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba7f0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.33333333333333337, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba430>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba8e0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  36\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8590>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8310>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.2800082266330719\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8270>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8064516129032258, 0.8361344537815125, 0.85]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b85e0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.2857142857142857, 0.16666666666666666, 0.28571428571428575]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba5c0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.4166666666666667, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9d50>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba7f0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  37\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f886bb0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8bade0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.3554011508822441\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8a40>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8387096774193549, 0.8865546218487395, 0.8648648648648648]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9d00>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.16666666666666666, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baca0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.6666666666666666, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baca0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baf20>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  38\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8270>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baca0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.3018002510070801\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba070>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8064516129032258, 0.9369747899159664, 0.8421052631578947]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8720>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.16666666666666666, 0.5]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8720>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.5714285714285714, 0.16666666666666669, 0.7272727272727273]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba0c0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baf70>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "\n",
      "Epoch  39\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b9f30>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "Layer 1 input: torch.Size([10, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([10, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([10, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([10, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba6b0>\n",
      "Size of x after pooling3: torch.Size([10, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([10, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([10, 1])\n",
      "outputs.shape: torch.Size([10, 1])\n",
      "['acc', 'auc', 'fmeasure']\n",
      "Training Loss  0.32575753331184387\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba9d0>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Train -  [0.8387096774193549, 0.9369747899159664, 0.8648648648648648]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8baa70>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Validation -  [0.42857142857142855, 0.25, 0.3333333333333333]\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba890>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n",
      "Test -  [0.42857142857142855, 0.5, 0.6]\n",
      "Layer 1 input: torch.Size([31, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([31, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([31, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([31, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8b8770>\n",
      "Size of x after pooling3: torch.Size([31, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([31, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([31, 1])\n",
      "Layer 1 input: torch.Size([7, 1, 481, 64])\n",
      "Layer 1 output: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 input: torch.Size([7, 1, 16, 481])\n",
      "Layer 2 output: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 input: torch.Size([7, 4, 4, 121])\n",
      "Layer 3 output: torch.Size([7, 4, 2, 30]) layer 3 size:  <built-in method size of Tensor object at 0x14f8ba8e0>\n",
      "Size of x after pooling3: torch.Size([7, 4, 2, 30])\n",
      "reshape value: 240\n",
      "FC Layer input: torch.Size([7, 240])\n",
      "testing Linear(in_features=240, out_features=1, bias=True)\n",
      "FC Layer output: torch.Size([7, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create model\n",
    "model = EEGNet (64, 481, verbose = True)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "batch_size = 10\n",
    "num_train_epochs = 40\n",
    "\n",
    "run_net(model, batch_size, num_train_epochs, optimizer, criterion, X_train, y_train, X_val, y_val, X_test, y_test, 'EEGBCI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
